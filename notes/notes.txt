Efficiency and Time Complexity (Lecture 1.1)
--------------------------------------------
- Phases of Software Development
    - Specification, Design, Impl, Analysis, Test, Doc
- Conditions
    - Invariant: Condition holds true before and after a loop (not necessarily during loop)
    - Precondition: Condition holds true before method
    - Postcondition: Condition holds true after method
- Specification of Method
    - Summary, Parameter Description, Precondition, Post-Condition / Return, Exception
    - Example
        - Summary: Area of a circle
        - Parameter Description: public static double area(double radius)
        - Precondition: radius > 0
        - Returns: Returns area of circle with given radius
        - Throws: IllegalRadius, Indicates radius is non positive


ADT (Lecture 1.2)
----------------
- Data Structure: Collection of data
    - Ex: Array
- Algorithm: Procedure of instructions for solving a problem in English, code, psuedocode
- ADT
    - Mathematical specification of a data structure
        - Type of data, operations on data, param on operations
    - What but not how
- Method Types
    - Accesssor (getX, getY)
    - Modification/Mutator (rotate90, shift)
    - Static (distance, midpoint)
    - Support (constructor, clone, equals, toString)

Bag ADT (Lecture 1.3)
---------------------
- Bag
    - It's just an array
    - Collection of items with same time
    - Invariants
        - Elements are stored in data[0 .. manyItems - 1]
        - manyItems <= data.length
- ArrayCopy
    - System.arrayCopy(src, srcPos, dest, destPos, numElems);

Linked List (Lecture 2.1)
-------------------------
- Linked Lists are mainly just memorization


Stacks (Lecture 3.1)
--------------------
- Imagine a stack of plates, can only add to the top or remove from top
- Array implementation: Using back as the "top" is more efficient (O(1)) vs. front of array (O(N))

Applications
    - OS: Keep track of method calls in program
    - Compilers: Converstion of arithmetic expression to machine code

OPERATIONS:
    - BASIC:
        - Constructor - create empty stack
        - isEmpty - is the stack empty?
        - push - push an element on top of stack (if stack is not full)
        - pop - remove top element from stack (if stack is not empty)
    - EXTENDED:
        - peek - examine top element of stack without removing it (if stack is not empty)
        - size: get size

Balanced Paranthesis:
    - Balanced if # left paren of each type = # right paren of each type
    - Each right and left match correctly

    Algorithm:
        iterate left -> right

        if char is left paren:
            push to stack

        else if right paren:
            if stack empty: return false
            else if type(stack.peek()) == type(char):
                stack.pop()
            else:
                return false

        after iterating, if (stack not empty), return false
    end of algorithm




Stacks Pt 2 (Lecture 3.2)
-----------------------------

Eval Expression (Fully Balanced) (Infix)
    NumStack, OpStack
    for(token : string)
        if token == num: numstack.push(token)
        if token == op: opstack.push(token)
        if token == '(' ignore
        if token == ')':
            num2 = numstack.pop()
            num1 = numstack.pop()
            op = opstack.pop()
            result = num1 op num2

Eval Expression (PostFix)
    NumStack
    for(token : string)
        if token == num: numstack.push(token)
        else:
            num2 = numstack.pop()
            num1 = numstack.pop()
            int res = num1 (token) num2
            numstack.push(res)

    answer = numstack.top()
    end of algorithm


Convert Infix -> Postfix
Precedence function:
'(' -> 1
'+ or -' -> 2
'* or /' -> 3


OpStack
String result
for(token : string)
    if Character.isDigit(token):
        result += token
    else if token == '(':
        op.push(token)
    else if token == ')':
        while(op.top() != '('):
            result += op.top()
            op.pop()
        op.pop()
    else:
        while(!op.isEmpty() && prec(op.top()) >= prec(token)):
            ans += op.top()
            op.pop()
        op.push(token)

while(!op.isEmpty()):
    result += op.top()
    op.pop()



Queues 1 (Lecture 4.1)
---------------------
- Imagine a line of people

Applications
    - OS: Print queue, process scheduling, input buffer
    - Modeling and simulating of computer and phone networks, road systems
    - Jai Alai


OPERATIONS
    - Constructor - create an empty queue
    - isEmpty - is the queue empty?
    - dequeue - remove the front element from queue
    - enqueue - add an element to the queue

- Best way is "circular"


Queues 2 (Lecture 4.2)
----------------------
- Math.random() -> random double in range [0.0, 1.0)
- Boolean source

- Lets say we call occurs() N times
- Return true 0.35 * N times, false (1 - 0.35) * N times

public boolean occurs(double prob) {
    return (Math.random() < prob);
}

- Return occurs(0.35)

Car wash simulation
    def carWash(int wash, double prob, int time):
        if(params are bad):
            throw exception
        
        IntQueue cars = new IntQueue();
        BooleanSource arrival = new BooleanSource(prob)
        int totalTime
        double averageTime
        int numCars
        int currentSecond
        int timeLeft

        for(currentSecond = 1; currentSecond <= time; currentSecond++) {
            if(arrival.occurs()) {
                cars.enqueue(currentSecond)
            } else if(timeLeft == 0 && !cars.empty) {
                timeLeft = wash
                totalTime = currentSecond - cars.dequeue()
                numCars++
            }
            if(timeLeft > 0) {
                timeLeft--
            }
        }

        averageTime = (double) totalTime / (double) numCars
        return averageTime


Recursion (Lecture 5.1)
-----------------------

Activation RecordsA
    - When a method calls another method, activation record is stored on system stack
    - Contains:
        - Where to return
        - Parameters passed
        - Value of local variables
            - X, N, location
    - In summary:
        - Temp storage for variables
        - Hold return location

Tail recursion
    - The recursive statement is the VERY last statement
    - Every tail recursive method can be rewritten as a for loop
    - Cannot contain any other expressions inside that statement:
    e.g.
    def fac(int n):
        if(n == 1) return 1
        return n * fac(n - 1)

    NOT TAIL RECURSIVE

    def tailfac(int n, int x):
        if(n == 1) return x
        return tailfac(n - 1, x * n)

    THIS IS TAIL RECURSIVE

Dynamic programming
    - Reduces recursive calls by saving return values

    Fibonacci
        int dp[n]
        int fib(int n):
            if(n <= 1) return n
            if(dp[n - 1] == -1) dp[n - 1] = fib(n - 1)
            if(dp[n - 2] == -1) dp[n - 2] = fib(n - 2)
            return dp[n - 1] + dp[n - 2]


Backtracking
- Exhaustive search of all solutions from partial solutions
- If any step leads to invalid solution, we "backtrak" to last partial solution
    findPath(x, y)
        if Maze[x][y] = T:
            output (x, y)
            return True
        else if Maze[x][y] = X:
            return false
        else:
            Maze[x][y] = X
            if findPath(x - 1, y) || findPath(x + 1, y) 
                || findPath(x, y - 1) || findPath(x, y + 1):
                output (x, y)
                return true
            else:
                return false




Binary Trees 1 (Lecture 6.1)
--------------------------
Terminology:
    - Formal definition:
        - A binary tree is either empty, or a node
            where left and right subtrees are binary trees

    - Given X, Y
    - X is an ancestor of Y if X is the parent of Y,
        or X is an ancestor of the parent of Y

    - X is a descendent of Y if X is a child of Y,
        or X is a descendent of a child of Y

    - Depth(Root) = 0

    - Full Binary Tree
        - All leaves same depth
        - Every non-leaf has 2 children

    - Complete Binary Tree
        - Every level has maximum nodes (besides lowest level)
        - Lowest level has all nodes left-most aligned
    
- If a full tree has n leaves, it has 2n-1 nodes
- If a tree has height h, it has max 2^(h + 1) - 1 nodes
    
Traversals
    - Preorder
        public void preorder() {
            System.out.println(data);
            if(left != null) left.preorder();
            if(right != null) right.preorder();
        }
    
    - Inorder
        public void inorder() {
            if(left != null) left.inorder();
            System.out.println(data);
            if(right != null) right.inorder();
        }

    - Postorder
        public void postorder() {
            if(left != null) left.postorder();
            if(right != null) right.postorder();
            System.out.println(data);
        }


Binary Trees 2 (Lecture 6.2)
----------------------------
Binary Search Trees
    - All nodes in left subtree are < root
    - All nodes in right subtree are > root
    - Insertion psuedocode
        def insert(int x):
            BTNode newNode = BTNode(x)
            BTNode cursor
            boolean done = false
            if(root == null):
                newNode = new BTNode(x)
                root = newNode
            else:
                cursor = root
                while(!done):
                    if(x < cursor.val):
                        if(cursor.left == null)
                            cursor.left = newNode
                            done = true
                        else:
                            cursor = cursor.left
                    else if(x > cursor.val)
                        if(cursor.right == null)
                            cursor.right = newNode
                            done = true
                        else:
                            cursor = cursor.right
                    else:
                        done = true     // that means NOT UNIQUE!!!!!!!

    - Time complexity:
        Full binary tree: O(logn)
        Worst case: O(n)

    - Removing psuedocode
        - 4 cases:
            - 1. Item not in tree
                return false

            - 2. Item is root, has no left child
                - Set root as right child

            - 3. Item is non-root, no left child
                - a) item == parent.left
                    - parent.left = item.right
                
                - b) item == parent.right
                    - parent.right = item.right

            - 4. Item has a left child
                - Find maximum value in item.left subtree
                    - This is called "rightmost node"
                - item.data = item.left.rightMostData()
                - item.left = item.left.removeRightMost()



Balanced Trees 1 (Lecture 7.1)
------------------------------

Heap
    - Binary tree such that
        - data in each node is greater than data in node's children
        - tree is complete

    - Storage
        - Array
        - root: index 0
        - node in index i:
            - left child: 2i + 1
            - right child: 2i + 2
            - parent: (i - 1) / 2

    - OPERATIONS
        - Constructor - Create empty heap
        - Insert
        - Remove MAXIMUM data element

    - Insert Algorithm
        - Place element in first empty position
        - Compare element with parent
            - If element > parent, swap(element, parent)
        - Repeat until element < parent or pos(element) == root

    - Remove Algorithm
        - Place root in temp variable
        - Move last element to root
        - While last element < children
            - swap(last element, max(children))
        - Return temp

    - Time Complexity
        - Assume Heap has N nodes
        - log(N) levels
        - INSERT: log(N)
        - REMOVE: log(N)

Priority Queue
    - Ordinary queue, but only remove maximum element

    - Array for PQ
        - Enqueue: O(1)
        - Dequeue: O(n)

    - Sorted Array for PQ
        - Enqueue: O(n)
        - Dequeue: O(1)

    - Heap
        - Enqueue and Dequeue: O(logn)



Balanced Trees 2 (Lecture 7.2)
------------------------------
- B-Tree
    - Balanced multi-way search tree
    - Node can hold multiple items
    - Node can have multiple children

    - Applications
        - Reduce disk IO operations
        - Used by database systems
        - Secondary storage

    - Rules
        - min(root.elements) = 1
        - min(other_node.elements) = MINIMUM
        - max(other_node.elements) = 2 * MINIMUM elements
        - given a node (non-leaf)
            - # subtrees = node.elements + 1
            - item[i]
                - greater than all elements in subtree[i]
                - less than all elements in subtree[i + 1]
        - every leaf has same depth

    - Elements are in increasing order in each node
    - Let's say a node has K elements
    - The 0th child will have all items < node[0]
    - The 1st child will have all items > node[1] && items < node[2]

    - Insertion
        - First insert element into proper node
        - If node now breaks B-Tree rules, select the element[size / 2] (median), and push it up
        - Recursively apply this step
        - Fix tree if needed

    Searching
        - searching for "item"
        - k: number of items in node
        - i: first index such that data[i] >= item
            - if all data[i] < item, i = k
        - if data[i] == item: return true
        - else search on subtree[i]

- 2-3-4 Tree
    - B tree BUT eliminate size requirements
    - Each node can have 2, 3, 4 elements
    - All leaves are at same depth
    - Adding example
        30 50 70
        10 15 20 | 40 | 60 | 80 90 

        Add 100

        30 50 70
        10 15 20 | 40 | 60 | 80 90 100

        Add 25

        30 50
        20 | 40 | 70
        10 15 | 25 | 60 | 80 90 100

    - Same insertion rules as B-Tree

- Red-Black Trees
    - Definition
        - Every node is red or black
        - Root is black
        - If node is red, children must be black
        - Every path from node to null link must have same # black nodes
        - Maximum height of logn
    - Rotations
        - Decrease height of tree
        - Large subtrees up, small subtrees down
        - Left-rotate code
            def rotateLeft(node):
                x = node.right
                y = x.left
                x.left = node
                node.right = y
                node.p = x
                if y != null: y.p = node
        - Right-rotate code
            def rotateRight(node):
                x = node.left
                y = x.right
                x.right = node
                node.left = y
                node.p = x
                if y != null: y.p = node
    - Insertion of node Z
        - Color Red and recolor/rotate nodes to fix
        - 4 Scenarios
            - Z = root
                - Color black
            - Z.uncle = red
                - Recolor parent, grandparent, uncle
            - Z.uncle = black (triangle)
                - Z is left child, parent is right child (vice versa too)
                - swap(Z, Z.parent) and make place parent on appropriate side of Z
                    (following BST)
            - Z.uncle = black (line)
                - Rotate Z.grandparent in opposite direction of Z
                - Basically, swap(Z.parent, Z.grandparent). Put Z on appropriate side of Z.parent
    - Just know properties + converting 2-3-4 -> Red-Black

- AVL Tree
    - Balanced BST
    - Invented by Adelson, Velski, Landis
    - Balanced: Height of subtrees differ by no more than 1
    - Depth with n nodes: O(logn)
    - Time Complexity:
        Search, insert, delete: O(logn)
    - Just know how to convert BST -> AVL
    
- Comparisons
    - Maximum number of nodes @ level n
        - Binary: 2^n
        - 2-3-4: 4^n
        - B-tree: (min + 1)^n
    - Maximum number of elements @ level n
        - Binary: 2^n
        - 2-3-4: 3 * 4^n
        - B-tree: 2 * min * (min + 1)^n


Sorting 1 (Lecture 8.1)
---------------------
- Selection Sort
    - Scan left to right. Assume subarray A[0 .. i] is the FINAL sorted result, 
        find the minimum element among A[i + 1 .. n - 1]. then swap(A[i + 1], A[min])
    - Example
        - 6 4 9 5 _1 8 2 7 3
        - 1 4 9 5 6 8 _2 7 3
        - 1 2 9 5 6 8 4 7 _3
        - 1 2 3 5 6 8 _4 7 9
        - 1 2 3 4 6 8 _5 7 9
        - 1 2 3 4 5 8 _6 7 9
        - 1 2 3 4 5 6 8 _7 9
        - 1 2 3 4 5 6 7 _8 9
        - 1 2 3 4 5 6 7 8 _9
    - Loop Invariant: Array is sorted for first i elements
    - In-place
    - Time Complexity: 
        - Worst: O(n^2)
            - (n - 1) * n / 2 comparisons = n^2
        - Best: O(n^2)

- Insertion Sort
    - Scan left to right. Assume subarray A[0 .. i] is sorted,
        "insert" element A[i + 1] into sorted subarray A[0 .. i]
    - In-place
    - Example 
        - _6 4 1 3 2 5
        - _4 6 1 3 2 5
        - _1 4 6 3 2 5
        - 1 _3 4 6 2 5
        - 1 _2 3 4 6 5
        - 1 2 3 4 _5 6
    - Loop Invariant: Subarray A[0 to i - 1] is sorted
    - Time Complexity:
        - Worst: O(n^2) (when the array is decreasing)
        - Average O(n^2)
        - Best O(n) (if the array is already sorted)

- Bubble Sort
    - Assume subarray A[0 .. i] is sorted. Iterate from j = n - 1 -> j = i + 1,
        swap(A[j], A[j - 1]) if A[j - 1] > A[j]
    - In-place
    - Example
        - 6 4 1 3 2 5
    - Time Complexity:
        - Worst: O(n^2)
        - Special Cases:
        

Sorting 2 (Lecture 8.2)
---------------------
- Merge Sort
    - Recursively split array into partitions that are half the parent partition size
    - Sort these split partitions, then merge them
    - NOT in place
    - Time Complexity
        - Everything: O(nlogn)

- Quick Sort
    - Choose an arbitrary pivot, such as first index in partition. Init two pointers, 
        lo and hi that start at either ends of partition. Increment lo until A[lo] > pivot.
        Decrement hi until A[hi] < pivot. Then swap(A[lo], A[hi]). Continue until lo meets hi.
        Then swap(A[pivot], A[end of first partition])

- Heap Sort
    - Make a Heap efficiently, then remove all elements iterate across A from n - 1 => 0
        - Efficient make heap: https://stackoverflow.com/questions/49774237/prove-that-binary-heap-build-max-comparsion-is-2n-2
    - Time Complexity
        - Everything: O(nlogn)

- Counting Sort
    - Given array of n elements with integers in range [0, k - 1]. Count frequency of each element.
        Then let start[] be a prefix sum that defines start position of each integer in new array.
        For each A[i], let pos = start[A[i]]. result[pos] = A[i], and start[A[i]]++
    - NOT in place
    - Time Complexity:
        - Everything: O(n + k)


Searching 1 (Lecture 9.1)
-------------------------
- Tables/Dict
    - ADT where items are stored according to a key
    - items are called records
    - Records can have multiple fields
    - Desired key value = target
    - Impl using array, heap, tree

- Sequential Search
    - On array, self explanatory
    - On table
        public static int search(someClass[] a, int target) {
            int i = 0;
            bool found = false;
            while((i < a.length) && !found) {
                if(a[i].getKey() == target) found = true;
                else i++;
            }
            if(found) return i;
            else return -1;
        }

- Binary Search
    - Precondition: sorted
    - Postcondition: pos of target
    - Psuedocode
        search(a, first, size, target):
            if size <= 0: return -1
            mid = first + size / 2
            if target == a[mid]: return mid
            else if target < a[mid]: return search(a, first, size / 2, target)
            else: return search(a, mid + 1, (size - 1) / 2, target)

- Hashing
    - Hash function maps key -> pos
    - If hash(k1) = hash(k2), collision has occured
    - Goals
        - Search, insert (no collision) is O(1)
    - Hash Function
        - k % tablesize (if integer)
        - k.hashCode() % tablesize (if Object)
        - Tablesize should be prime
            - Proof
                Let p = tablesize of hashtable
                Let x be any prime < p s.t. x | p
                For all k s.t. xk < p, xk + pi will make to xk in hashtable
                However, if p is prime, there exists no x < p,
                and the only pattern will be kp (mapping to 0)
    - Collision Resolution
        - Given hash(k) = p
        - Linear Probing
            - If table[p] contains diff, key, examine p+1, p+2 ... until empty
            - H(k, i) = (h'(k) + c * i) mod tableSize
        - Quadratic Probing
            If table[p] contains diff, key, examine p+1, p+4, p+9 ... until empty
            - H(k, i) = (h'(k) + c1 * i + c1 * i^2) mod tableSize
    - Removing from Hashtable
        - May cause problems with probing
        - Add a boolean array to check if position has been used previously
        - During probing, if table[p] empty and used[p], continue search
    - Load Factor
        - Load factor (\alpha) = num_elements / tableSize
        - For linear probing, as \alpha approaches 1, # collisions increase






Recitation Notes
----------------